{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5ad563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab6499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras.backend as K\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03156e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A DATAFRAME\n",
    "df=pd.read_csv('add train data set absolute path',encoding='utf-8')\n",
    "df.columns=['rating','title','review']\n",
    "df=df.drop(columns=['title'])\n",
    "df.insert(2,'sentiment',0)\n",
    "df.loc[df['rating']>3, 'sentiment']=1\n",
    "df = df.drop(columns=['rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e8d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSIDERING 8 LAKH REVIEWS FOR THE DATAFRAME\n",
    "df = df.loc[:799999]\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0feb432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A GRAPH PLOT FOR REVIEWS BASED ON SENTIMENT '0' OR'1'\n",
    "sns.countplot(df['sentiment'], palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962794a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATING THE LENGTH of each review and align them under \"TEXT_LENGTH \"\n",
    "df['text_length'] = df['review'].apply(len)\n",
    "df[['sentiment','text_length','review']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22bb226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting a graph for TEXT_LENGTH and REVIEWS\n",
    "df['text_length'].hist(bins=50, color=\"m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17960ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A BAR PLOT for 'TEXT_LENGTH' and 'REVIEWS' for two sentiments '0' and '1'\n",
    "g = sns.FacetGrid(df,col='sentiment')\n",
    "g.map(plt.hist,'text_length', color = 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOXPLOT\n",
    "sns.boxplot(x='sentiment',y='text_length',data=df,palette='winter_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe47c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORDCLOUD\n",
    "text = df['review'].to_string()\n",
    "wordcloud = WordCloud(\n",
    "background_color='white',max_font_size = 24,relative_scaling=0.5,\n",
    "stopwords=set(stopwords.words('english'))).generate(text)\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "X = df['review']\n",
    "y = to_categorical(df['sentiment'])\n",
    "\n",
    "#y=df['sentiment']\n",
    "num_classes = df['sentiment'].nunique()\n",
    "seed = 101\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e583d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data as train data and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y,\n",
    "random_state=seed)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da99c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORD EMBEDDING\n",
    "max_features = 15000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "print(dict(tokenizer.word_index.items()).values())\n",
    "print(list(dict(tokenizer.word_index.items()).keys())[0:200])\n",
    "totalNumWords = [len(one_comment) for one_comment in X_train]\n",
    "print(totalNumWords)\n",
    "plt.hist(totalNumWords,bins = 30)\n",
    "plt.show()\n",
    "max_words = 100\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING THE MODEL\n",
    "\n",
    "batch_size = 1500\n",
    "epochs =1\n",
    "epochs2=2\n",
    "epochs5=5\n",
    "epochs10=20\n",
    "max_features = 15000\n",
    "embed_dim = 100\n",
    "num_folds = 10\n",
    "np.random.seed(seed)\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1]))\n",
    "\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "\n",
    "optimizer='adam',\n",
    "\n",
    "metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91272cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING THE DATASET TO THE MODEL\n",
    "model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "epochs=epochs10, batch_size=batch_size, verbose=1)\n",
    "fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "axs[0].set_title('Model Accuracy')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].set_xlabel('Epoch'+str(epochs10))\n",
    "axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.\n",
    "history['acc'])/10)\n",
    "axs[0].legend(['train', 'val'], loc='best')\n",
    "axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "axs[1].set_title('Model Loss')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].set_xlabel('Epoch'+str(epochs10))\n",
    "axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.\n",
    "history['loss'])/10)\n",
    "axs[1].legend(['train', 'val'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c1c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "y_pred_test = model.predict_classes(X_test, batch_size=batch_size, verbose=0)\n",
    "print('Accuracy:\\t{:0.1f}%'.format(accuracy_score(np.argmax(y_test,axis=1),y_pred_test)*100))\n",
    "print('\\n')\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred_test))\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "for j in range(confmat.shape[1]):\n",
    "ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e67c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX\n",
    "confmat = confusion_matrix(np.argmax(y_test,axis=1), y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
